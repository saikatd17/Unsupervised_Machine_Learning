{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c30c4758",
   "metadata": {},
   "source": [
    "# Collaborative_Filtering_Movies_Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d523e82",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "\n",
    "<b>NearestNeighbors</b> implements unsupervised nearest neighbors learning. \n",
    "\n",
    "The choice of neighbors search algorithm is controlled through the keyword <b>'algorithm'</b>, which must be one of ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "\n",
    "https://scikit-learn.org/stable/modules/neighbors.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258178ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import ? # Replace ? NearestNeighbors\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4593c276",
   "metadata": {},
   "source": [
    "## MovieLens data\n",
    "\n",
    "MovieLens data sets were collected by the <b>GroupLens Research Project\n",
    "at the University of Minnesota</b>.\n",
    "\n",
    "This data set consists of:\n",
    "* 100,000 ratings (1-5) from 943 users on 1682 movies.\n",
    "* Each user has rated at least 20 movies.\n",
    "\n",
    "\n",
    "The data was collected through the <b>MovieLens web site</b> (movielens.umn.edu) during the <b>seven-month period from September 19th,\n",
    "1997 through April 22nd, 1998</b>. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e894d5",
   "metadata": {},
   "source": [
    "## Read the dataset and process it for next steps\n",
    "\n",
    "<b>u.data</b> -- \n",
    "\n",
    "The full u data set, <b>100000 ratings by 943 users on 1682 movies </b>.\n",
    "Each user has rated at least 20 movies. Users and items are numbered consecutively from \n",
    "\n",
    "1. The data is randomly ordered. This is a tab separated list of user id | item id | rating | timestamp.\n",
    "\n",
    "The time stamps are unix seconds since 1/1/1970 UTC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0032faa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "header = ['user_id','item_id','rating','timestamp']\n",
    "dataset = pd.read_csv('u.data',sep ='\\t',names = header)\n",
    "\n",
    "print(dataset.head())\n",
    "\n",
    "# dataset.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774b6bee",
   "metadata": {},
   "source": [
    "## Data is transformed into the matrix format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04601050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the count of users\n",
    "n_users = dataset.user_id.unique().shape[0]\n",
    "\n",
    "#print(n_users)\n",
    "# Obtain the count of movies\n",
    "n_items = dataset.item_id.unique().shape[0]\n",
    "\n",
    "#print(n_items)\n",
    "\n",
    "#n_items = dataset['item_id'].max()\n",
    "\n",
    "# Create a matrix of size n_users X n_items\n",
    "rating_matrix = np.?((n_users,n_items)) # Replace ? by zeros\n",
    "\n",
    "# Fill each cell in the matrix with value of the corresponding user-movie rating from the dataset\n",
    "for line in dataset.itertuples():\n",
    "    rating_matrix[line[1]-1,line[2]-1] = line[3]\n",
    "\n",
    "# Alternatively we can use a binary matrix, containing the information whether user rated a movie or not\n",
    "'''\n",
    "for line in dataset.itertuples():\n",
    "    if line[3] >=3:\n",
    "        rating_matrix[line[1]-1,line[2]-1] = 1\n",
    "    else:\n",
    "        rating_matrix[line[1]-1,line[2]-1] = 0\n",
    "'''\n",
    "\n",
    "# Check how the matrix looks after user-movie rating is populated\n",
    "print(\"Original rating matrix : \")\n",
    "print(?) # Replace ? by rating_matrix\n",
    "# rating_matrix[195,241]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16764939",
   "metadata": {},
   "source": [
    "## Converting the dense rating matrix into a sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e1db2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using scipy.sparse.csr_matrix\n",
    "\n",
    "rating_sparse = csr_matrix(rating_matrix)\n",
    "print(rating_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c0559c",
   "metadata": {},
   "source": [
    "## Compute item-based similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101b2ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding nearest neighbours based on cosine similarity distance\n",
    "\n",
    "knn = ?(metric='cosine', algorithm='brute', n_neighbors=3, n_jobs=-1) # Replace ? by NearestNeighbors\n",
    "knn.fit(rating_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b48691",
   "metadata": {},
   "source": [
    "## Generate recommendations for an user based on items being liked\n",
    "After, the similarity between items is computed, we can generate recommendations for the target user.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53721669",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# We sort each user by descending order of rating  \n",
    "dataset_sort_des = dataset.sort_values(['user_id', 'rating'], ascending=[True, False])\n",
    "\n",
    "#print(dataset_sort_des)\n",
    "\n",
    "# Now we get the movies being liked by an user \n",
    "target_user = ? # Replace ? by 1; lets check for the user having id 1\n",
    "\n",
    "filter1 = dataset_sort_des[dataset_sort_des['user_id'] == target_user].item_id\n",
    "#print(filter1)\n",
    "\n",
    "filter1 = filter1.tolist()\n",
    "\n",
    "# We select the top 5 movies liked by the target user\n",
    "filter1 = filter1[0:?] # Replace ? by 5\n",
    "\n",
    "# print the id of the top 5 movies\n",
    "#print(filter1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6180a230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my choice\n",
    "#filter2 = [128,144,29,71,95]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e258932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets show corresponding movie name by fetching information from the movies dataset.\n",
    "\n",
    "# Load the Excel data into a pandas DataFrame\n",
    "movie_names_file = 'MoiveNames.csv'\n",
    "df = pd.read_csv(movie_names_file)\n",
    "\n",
    "# Create a dictionary mapping movie IDs to movie names\n",
    "movie_id_to_name = dict(zip(df['ID'], df['Title']))\n",
    "\n",
    "# Let's generate recommendations for target user based on 5 items being liked by the user. \n",
    "# Remmove the following multi-line comment (''' ...''') and execute\n",
    "'''\n",
    "print(\"Top Five Movies liked by user\",target_user)\n",
    "print()\n",
    "print(\"Movie Ids: \",filter1)\n",
    "\n",
    "print()\n",
    "'''\n",
    "\n",
    "# List of movie IDs for which you want to extract movie names\n",
    "input_movie_ids = filter1\n",
    "\n",
    "# input_movie_ids = filter2\n",
    "\n",
    "# Extract movie names based on input movie IDs\n",
    "extracted_movie_names = [movie_id_to_name[movie_id] for movie_id in input_movie_ids if movie_id in movie_id_to_name]\n",
    "\n",
    "# Print the extracted movie names\n",
    "print(\"Title:\")\n",
    "for movie_name in extracted_movie_names:\n",
    "    print(movie_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0685adf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, for each item being liked by the target user, we recommend 2 similar movies. \n",
    "\n",
    "distances1=[]\n",
    "indices1=[]\n",
    "\n",
    "# for each movie liked by the target user i.e. the loop runs 5 times (implementing item-based filtering)\n",
    "for i in filter1:  \n",
    "  distances , indices = knn.kneighbors(rating_sparse[i],n_neighbors=3) \n",
    "  indices = indices.flatten()\n",
    "  indices= indices[1:]\n",
    "  indices1.extend(indices)\n",
    "\n",
    "print(\"Top Ten Movies to be recommended to \",target_user)\n",
    "print()\n",
    "print(\"Movie Ids: \",indices1)\n",
    "\n",
    "# List of movie IDs for which you want to extract movie names\n",
    "input_movie_ids = indices1\n",
    "\n",
    "# Extract movie names based on input movie IDs\n",
    "extracted_movie_names = [movie_id_to_name[movie_id] for movie_id in input_movie_ids if movie_id in movie_id_to_name]\n",
    "\n",
    "print()\n",
    "# Print the extracted movie names\n",
    "print(\"Title:\")\n",
    "for movie_name in extracted_movie_names:\n",
    "    print(movie_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3b8c40",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. https://www.kaggle.com/datasets/prajitdatta/movielens-100k-dataset?resource=download\n",
    "2. https://www.analyticsvidhya.com/blog/2021/05/item-based-collaborative-filtering-build-your-own-recommender-system/\n",
    "3. https://www.analyticsvidhya.com/blog/2020/08/recommendation-system-k-nearest-neighbors/#5c17"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
