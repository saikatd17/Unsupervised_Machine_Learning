{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71176d97",
   "metadata": {},
   "source": [
    "# Association Mining (Market Basket Analysis) Using Books Dataset\n",
    "\n",
    "Upload/Save CharlesBookClub.csv in your Python folder to access from this program\n",
    "\n",
    "Columns in the dataset:\n",
    "\n",
    "'Seq#', 'ID#', 'Gender', 'M', 'R', 'F', 'FirstPurch', 'ChildBks',\n",
    " 'YouthBks', 'CookBks', 'DoItYBks', 'RefBks', 'ArtBks', 'GeogBks',\n",
    " 'ItalCook', 'ItalAtlas', 'ItalArt', 'Florence', 'Related Purchase',\n",
    " 'Mcode', 'Rcode', 'Fcode', 'Yes_Florence', 'No_Florence'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e02148",
   "metadata": {},
   "source": [
    "## Step 1. Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0293842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following 'commented' line of code after removing the '#', if mlxtend package is not available by default in your Python environment\n",
    "#!pip install mlxtend \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from mlxtend.frequent_patterns import ?    # Replace '?' by 'apriori'; Apriori function to extract frequent itemsets for association rule mining\n",
    "from mlxtend.frequent_patterns import ?    # Replace '?' by 'association_rules', Function to generate association rules from frequent itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb57bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to suppress warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419486a4",
   "metadata": {},
   "source": [
    "## Step 2. Load and explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cb0859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset from csv file to a dataframe\n",
    "\n",
    "books_df = pd.read_csv('CharlesBookClub.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94f81f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how the data looks, head() by default prints the first 5 rows\n",
    "\n",
    "books_df.? # Replace '?' by 'head()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69449886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can use the attribute 'columns' to check what are the columns in the dataframe\n",
    "\n",
    "books_df.? # Replace '?' by 'columns'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1fccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly can use the method 'info()' to check details about the columns in the dataframe\n",
    "\n",
    "books_df.?  # Replace '?' by 'info()'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c62368",
   "metadata": {},
   "source": [
    "## Step 3. Preprocess the data\n",
    "\n",
    "After exploring the data, we need to preprocess it in a particular format for applying Apriori algorithm\n",
    "\n",
    "First we select the columns of interest, then we generate a binary incidence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebbd58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the columns that are of interest and would be used to generate the binary incidence matrix\n",
    "\n",
    "books_matrix = books_df[['Seq#', 'ChildBks','YouthBks', 'CookBks', 'DoItYBks', 'RefBks', 'ArtBks', 'GeogBks','ItalCook', 'ItalAtlas', 'ItalArt', 'Florence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77958d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the new dataframe contains the desired columns with their corresponding values\n",
    "\n",
    "books_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01a6a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set the column 'Seq#'' as the index, of the dataframe created for generating the binary incidence matrix\n",
    "\n",
    "books_matrix.set_index('Seq#', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ed0d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For applying Apriori algorithm, preprocess the data to create the binary incidence matrix\n",
    "\n",
    "# The following function replace the actual number of books purchased by 0 or 1 depending on whether a specific type of book is purchased or not\n",
    "def encode_units (x):\n",
    "    \n",
    "    if x==0:\n",
    "        return 0\n",
    "    elif x>0:\n",
    "        return 1\n",
    "\n",
    "# the binary incidence matrix is created which denotes for every transaction what type of books are purchased\n",
    "books_incidencematrix = books_matrix[['ChildBks','YouthBks', 'CookBks', 'DoItYBks', 'RefBks', 'ArtBks', 'GeogBks','ItalCook', 'ItalAtlas', 'ItalArt', 'Florence']].applymap(encode_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37627702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check first few rows of the binary incidence matrix to verify it is correctly created\n",
    "\n",
    "books_incidencematrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc5fcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further check to verify that the binary incidence matrix is correctly created i.e. there are no null values\n",
    "\n",
    "books_incidencematrix.isnull().sum() # the binary incidence matrix if correctly created should not contain any null values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a03cbf",
   "metadata": {},
   "source": [
    "## Step 4. Apply Apriori Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f164ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create frequent itemsets using - from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "#Use apriori function, lets set minimum support of 400/4000 = 10% i.e., min_support = 0.1\n",
    "itemsets = apriori(books_incidencematrix, min_support = ?, use_colnames = True) # Replace '?' by '0.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7698bc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the contents of itemsets\n",
    "\n",
    "itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c81356",
   "metadata": {},
   "source": [
    "## Step 5. Generate the association rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e01b704",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To generate the association rules we use association_rules function with metric as 'confidence' and lets set min_threshold '0.5' \n",
    "\n",
    "rules_confidence = association_rules(itemsets, metric = 'confidence',min_threshold =?) # Replace '?' by '0.5'\n",
    "\n",
    "rules_confidence.drop(columns = ['antecedent support','consequent support','conviction','leverage'])\n",
    "                                 \n",
    "# Sort the rules generated based on minimum confidence = 0.5 by value of lift\n",
    "rules_confidence.sort_values(by=['lift'], ascending = False).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f3ead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many rules have been formed from the itemsets based on the desired metric and threshold i.e., minimum confidence 0.5\n",
    "\n",
    "rules_confidence.shape # The attribute shape returns the number of rows and columns in rules_confidence, where number of rules = number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84f20e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also generate the rules using association_rules function with metric as 'lift' with min_threshold = 1\n",
    "\n",
    "rules_lift = association_rules(itemsets, metric =?, min_threshold = 1) # Replace '?' by 'lift'\n",
    "\n",
    "# Sort the rules generated based on minimum lift = 1 by value of lift\n",
    "rules_lift.sort_values(by=['lift'], ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c861aac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many rules have been formed from the itemsets based on the desired metric and threshold i.e., minimum lift = 1\n",
    "\n",
    "rules_lift.? # Replace '?' by 'shape'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffe7b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 25 rules (if number of rules more than 25)\n",
    "\n",
    "print(rules_lift.sort_values(by=['lift'], ascending = False).head(?))  # Replace '?' by '25'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335dd3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rules that satisfy confidence > 0.1 \n",
    "\n",
    "rules = association_rules(itemsets, metric = 'confidence',min_threshold =0.1)\n",
    "\n",
    "rules.drop(columns=['antecedent support','consequent support','conviction','leverage'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d453d238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column containing the length of the antecedent\n",
    "\n",
    "rules['len']=rules['antecedents'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4e84ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rules that satisfy 1. atleast 2 antecedents, 2. confidence > 0.5 and, 3. lift > 1\n",
    "\n",
    "rules[(rules['len']>=2)&(rules['confidence']>0.5)&(rules['lift']>1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1598d37",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "rasbt.github.io/mlxtend\n",
    "\n",
    "https://medium.com/@jihargifari/how-to-perform-market-basket-analysis-in-python-bd00b745b106\n",
    "\n",
    "https://analyticsindiamag.com/hands-on-guide-to-market-basket-analysis-with-python-codes/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
